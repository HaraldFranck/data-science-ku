{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f211c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a295dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in \"EFGHIJKLMN\":\n",
    "    response = requests.get(f'https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&from={i}')\n",
    "    contents = response.text\n",
    "    d[f\"{i}\"] = BeautifulSoup(contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3545afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = {}\n",
    "for i in d:\n",
    "    pages[f\"{i}\"] = d[f'{i}'].find(id=\"mw-pages\").find_all(\"a\")\n",
    "\n",
    "links = []\n",
    "for elm in pages:\n",
    "    for i in pages[elm]:\n",
    "        i.find_all('a', href=\"/wiki/\")\n",
    "        links.append(i['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddabdecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2040):\n",
    "    for ind, elm in enumerate(links):\n",
    "        if elm.startswith(\"/w/\"):\n",
    "            del links[ind]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33dd4211",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "content = []\n",
    "for i in links:\n",
    "    response = requests.get(\"https://en.wikinews.org\" + i)\n",
    "    contents = response.text\n",
    "    soup = BeautifulSoup(contents, \"html.parser\")\n",
    "    title.append(soup.find(id=\"firstHeading\").get_text())\n",
    "    content.append(soup.find(class_=\"mw-parser-output\").get_text())\n",
    "    #date.append(soup.find(class_=\"published\").get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dcce36d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = []\n",
    "for i in links:\n",
    "    response = requests.get(\"https://en.wikinews.org\" + i)\n",
    "    contents = response.text\n",
    "    soup = BeautifulSoup(contents, \"html.parser\")\n",
    "    try:\n",
    "        date.append(soup.find(class_=\"published\").get_text())\n",
    "    except: \n",
    "        date.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ff8ec9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_triples = list(zip(title, content, date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3bb31551",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list_of_triples,\n",
    "                  columns=['Title', 'Content', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ee44ceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E-Passport cloned in five minutes</td>\n",
       "      <td>Monday, December 18, 2006 \\n\\nNorwegian biomet...</td>\n",
       "      <td>Monday, December 18, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E.C. President does not advise Portuguese refe...</td>\n",
       "      <td>Monday, December 6, 2004 \\nLISBON — The Presid...</td>\n",
       "      <td>Monday, December 6, 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Earl Anthony Wayne confirmed as U.S ambassador...</td>\n",
       "      <td>Thursday, August 4, 2011 \\n\\n\\nMexico\\nRelated...</td>\n",
       "      <td>Thursday, August 4, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Early Canadian federal election set for Octobe...</td>\n",
       "      <td>\\nCanada\\nRelated articles\\n\\n\\n15 June 2022: ...</td>\n",
       "      <td>Sunday, September 7, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Early Iraq elections marred by violence</td>\n",
       "      <td>Friday, March 5, 2010 \\n\\n\\nIraq\\nRelated arti...</td>\n",
       "      <td>Friday, March 5, 2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                  E-Passport cloned in five minutes   \n",
       "1  E.C. President does not advise Portuguese refe...   \n",
       "2  Earl Anthony Wayne confirmed as U.S ambassador...   \n",
       "3  Early Canadian federal election set for Octobe...   \n",
       "4            Early Iraq elections marred by violence   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Monday, December 18, 2006 \\n\\nNorwegian biomet...   \n",
       "1  Monday, December 6, 2004 \\nLISBON — The Presid...   \n",
       "2  Thursday, August 4, 2011 \\n\\n\\nMexico\\nRelated...   \n",
       "3  \\nCanada\\nRelated articles\\n\\n\\n15 June 2022: ...   \n",
       "4  Friday, March 5, 2010 \\n\\n\\nIraq\\nRelated arti...   \n",
       "\n",
       "                        Date  \n",
       "0  Monday, December 18, 2006  \n",
       "1   Monday, December 6, 2004  \n",
       "2   Thursday, August 4, 2011  \n",
       "3  Sunday, September 7, 2008  \n",
       "4      Friday, March 5, 2010  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3fd2f2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n",
      "1987\n"
     ]
    }
   ],
   "source": [
    "print(len(title))\n",
    "print(len(content))\n",
    "print(len(date)-date.count(''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc8ae6",
   "metadata": {},
   "source": [
    "There are 2000 different articles in the dataset, and apparently "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
